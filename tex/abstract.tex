%# -*- coding: utf-8-unix -*-
% !TEX program = xelatex
% !TEX root = ../thesis.tex
% !TEX encoding = UTF-8 Unicode
%%==================================================
%% abstract.tex for SJTU Master Thesis
%%==================================================

\begin{abstract}

{\li}[]是一种基于机器学习的索引结构，它将索引视为从键到数据位置的函数映射，通过多层级{\model}结构，{\rmi}，拟合这一函数关系。
作为一种新型索引结构，相比传统的B树索引，{\li}不仅能够减少了查询的执行时间，还降低了索引结构的空间消耗。
这些特性为{\li}带来了许多吸引力，激起了系统研究社区的广泛讨论[]。

然而，{\li}的设计与实现较为初步。
{\li}假设工作场景是只读的，且访问是均匀分布的。
然而，在真实场景下，伴随着写操作的执行，索引数据是频繁变化的，从而带来数据分布的动态变化。
同时，真实场景下工作负载是具有访问模式的，从而带来数据访问偏向性。
这些广泛存在于真实场景里的动态场景为{\li}的应用带来了许多挑战与机遇。

本文对{\li}在真实场景下的性能表现进行了探究，分析讨论了访问模式与动态数据分布这两个广泛存在于真实场景的工作负载特性对{\li}的影响与成因，
并通过实验验证了分析结果，为解决方案的提出提供了支撑与指导。

针对真实场景对{\li}提出的挑战，本文提出了一个新的针对动态场景的学习索引系统{------}{\sys}。
通过数据拉伸方法，{\sys}将访问模式信息加入了{\li}的构建过程；
通过模型缓存机制，{\sys}克服了高昂的{\li}架构搜索代价；
通过完整的系统设计，{\sys}应用以上两个技术创新点，构建了一个面向真实场景的动态的学习索引系统。
实验结果证明，{\sys}能够带来高达XXX\%的性能提升，并节省，能够高效地应对真实场景对{\li}带来的挑战。

\end{abstract}

\begin{englishabstract}

The recent proposal of learned index structures opens up a new perspective on how traditional range indexes can be optimized.
The pioneer study on learned index structures arouses a lot of excitements around how machine learning can resculpt system components that have been decades-old, such as bloom filters, join queries or even enable self-tuning databases.
The core insight of learned indexes is to view index as a distribution function from the keys to the index positions that can be approximated by deep neural networks.

However, the current learned indexes assume the data distribution is relatively static and the access pattern is uniform, while real-world scenarios consist of skew query distribution and evolving data.
These two issues hinder the wider adoption of the learned indexes for real-world workloads.
In this paper, we demonstrate that the missing consideration of access patterns and dynamic data distribution notably hinders the applicability of learned indexes.

Their preliminary study assumes a relatively static distribution function, while in many real world scenarios, the data is constantly evolving.
Typical approaches simply rely on re-training the whole model once the data distribution shifts notably from the training set used by the current model.
However, such re-training is costly, because not only the model parameters need to be \textit{fine-tuned}, but also that the model architecture needs to be searched again for better accuracy.
Depending on the size of the hyperparamter search space, a basic architecture search technique such as grid search can easily take up to 10-100x the model training time.

Besides the inefficiency in handling dynamic workloads, the learned index paper also assumes a uniform access pattern (or query distribution).
However, queries in real worlds tend to be skew, where some keys are much more frequently queried than the others.
As a result, mispredicting a hot key is way more expensive, and we show that the originally proposed learned index model performs poorly under such scenarios.

In this paper, we propose \sys, a new learned index system for dynamic workloads where the data distribution and access pattern may be skew and evolving.
To handle skewed access pattern, we first investigate and discuss why the original model fails to address this issue.
To improve the latency for skew queries, \sys augments the training data with access frequencies.
For the issue of model re-training, our insight is that the same model architecture can be reused for similar data distribution and access pattern.
To address the slow model re-training when data distribution shifts, \sys caches the previously-trained models and incrementally fine-tunes them for similar access patterns and data distribution.
The preliminary result shows that, by augmenting dataset with the access frequency, the best model architecture has 45.1\% performance improvement; by caching and reusing previous training result, the rebuilding time is reduced to XXX.

\end{englishabstract}
